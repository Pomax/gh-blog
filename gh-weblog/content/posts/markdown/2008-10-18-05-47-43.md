# Done with kanji decomposing

The title might be misleading - I am done decomposing all 3774 kanji that rolled out of the data that I dicussed in <a href="http://pomax.nihongoresources.com/index.php?entry=1222520260" target="_blank">my earlier post</a>. That still leaves a small task of adding in the descriptor characters to indicate *how* the decompositions form the original characters, and then seeing which of the characters that were used in the decompositions don't actually exist in the original data set, so that I need to treat those too (I expect this to only a few hundred at most).

As for the progress: I have added descriptor characters to all kanji up to stroke count 10, which means about a third of the kanji are "done", with about two third still waiting to be "described". This is a much quicker process than writing up decompositions so I expect this to take no more than until next weekend and we're good to go for the real task:

Ordering the kanji based on which are most important to the language, optimised compositionally, so that you get to learn kanji that you will see used all over the place, before you learn ones that are rare, in such a way that you will mostly learn new kanji that use kanji you already know as components.

Sounds good? It does to me. Never did like the jouyou ordering >.>